{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matotheham/DataScienceProjects/blob/main/FA19_BCS_003_IDS_A3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1(i) 80 instances\n",
        "#1(ii) 7 attributes\n",
        "#1(iii) 2 values\n",
        "#1(iv) 4 attributes\n",
        "#1(v) 46:34 = 23:17 male:female\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "#2(i) RFC gives 91.6% accuracy. SVM gives 70.8% accuracy. MLP gives 66.6% accuracy.\n",
        "\n",
        "#2(ii) Now RFC accuracy is 93.7%. SVM is at 75%. MLP is at 43.7%. RFC and SVM \n",
        "#accuracy increased because we provided more instances to these classifiers and \n",
        "#model was able to learn better. While accuracy of MLP decreases because by \n",
        "#providing it more instances the loss of this model started to increase due to\n",
        "#which MLP accuracy dropped.\n",
        "\n",
        "#2(iii) beard and scarf are the two most important attributes. As men don't wear\n",
        "#scarf and women don't have beard.\n",
        "\n",
        "#2(iv) After excluding beard and scarf, RFC is giving 100% accuracy this is \n",
        "#probably happening because classifier is not being able to differentiate\n",
        "#between the classed. SVM is giving 62.5% accuracy while previously it was at \n",
        "#75% and MLP is giving 37.5% accuracy now. As we mentioned beard and scarf are\n",
        "#two most important attributes and on the basis of these two attributes our \n",
        "#classifiers are able to differentiate between the classes. We can see that if \n",
        "#we exclude these attributes our classifiers will not be able to differentiate\n",
        "#between the classes.\n",
        "\n",
        "#---------------------------------------------------------------------------------\n",
        "#3 Average cross validation score for Leave P-out is 0.9625 and for monte-carlo\n",
        "#cross validation it is 0.95.\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#4 Adding 5 instances in a separate file so that other part of code doesn't get\n",
        "#disrupted. Accuracy through naive bayes classifier is 80%\n",
        "\n"
      ],
      "metadata": {
        "id": "McHWQJ33pL6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9dHPfQfPTj5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import LeavePOut\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import GaussianNB "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/gender-prediction.csv')\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "s-jAilJDV0zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataset:\n",
        "  dataset['beard'] = dataset['beard'].replace(['yes'], 2222)\n",
        "  dataset['beard'] = dataset['beard'].replace(['no'], 1111)\n",
        "  dataset['hair_length'] = dataset['hair_length'].replace(['bald'], 11111)\n",
        "  dataset['hair_length'] = dataset['hair_length'].replace(['short'], 22222)\n",
        "  dataset['hair_length'] = dataset['hair_length'].replace(['medium'], 33333)\n",
        "  dataset['hair_length'] = dataset['hair_length'].replace(['long'], 44444)\n",
        "  dataset['scarf'] = dataset['scarf'].replace(['yes'], 222222)\n",
        "  dataset['scarf'] = dataset['scarf'].replace(['no'], 111111)\n",
        "  dataset['eye_color'] = dataset['eye_color'].replace(['black'], 1111111)\n",
        "  dataset['eye_color'] = dataset['eye_color'].replace(['blue'], 2222222)\n",
        "  dataset['eye_color'] = dataset['eye_color'].replace(['brown'], 3333333)\n",
        "  dataset['eye_color'] = dataset['eye_color'].replace(['gray'], 4444444)\n",
        "  dataset['eye_color'] = dataset['eye_color'].replace(['green'], 5555555)\n",
        "  dataset['gender'] = dataset['gender'].replace(['male'], 11111111)\n",
        "  dataset['gender'] = dataset['gender'].replace(['female'], 22222222)\n",
        "\n",
        "print(dataset)  "
      ],
      "metadata": {
        "id": "3h_GqIwYjfaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputAttributes = dataset[['height', 'weight', 'beard', 'hair_length', \n",
        "                           'shoe_size', 'scarf', 'eye_color']]\n",
        "outputAttribute = dataset['gender']\n",
        "\n",
        "exInpAttr = dataset[['height', 'weight', 'hair_length', 'shoe_size', 'eye_color']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(inputAttributes, \n",
        "                                                    outputAttribute, test_size = 0.2)\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(exInpAttr, \n",
        "                                                    outputAttribute, test_size = 0.2)"
      ],
      "metadata": {
        "id": "mL7ZDLoUoa6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators = 100)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "clf1 = RandomForestClassifier(n_estimators = 100)\n",
        "clf.fit(X_train1, y_train1)\n",
        "y_pred1 = clf.predict(X_test1)\n",
        "print(\"Accuracy (Excluded):\",metrics.accuracy_score(y_test1, y_pred1))"
      ],
      "metadata": {
        "id": "bY0g-GD4gXsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "clf1 = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train1, y_train1)\n",
        "y_pred1 = clf.predict(X_test1)\n",
        "print(\"Accuracy (Excluded):\",metrics.accuracy_score(y_test1, y_pred1))"
      ],
      "metadata": {
        "id": "ERlTlO2QpqEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(6,5), random_state=5, verbose=True, learning_rate_init=0.01)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "clf1 = MLPClassifier(hidden_layer_sizes=(6,5), random_state=5, verbose=True, learning_rate_init=0.01)\n",
        "clf.fit(X_train1, y_train1)\n",
        "y_pred1 = clf.predict(X_test1)\n",
        "print(\"Accuracy (Excluded):\",metrics.accuracy_score(y_test1, y_pred1))"
      ],
      "metadata": {
        "id": "T9vtMQs10TnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lpo = LeavePOut(p=2)\n",
        "lpo.get_n_splits(inputAttributes)\n",
        "clf = DecisionTreeClassifier(criterion=\"gini\", random_state=42,max_depth=3, min_samples_leaf=5)  \n",
        "score = cross_val_score(clf, inputAttributes, outputAttribute, cv=lpo) \n",
        "print(\"Cross Validation Scores are {}\".format(score))\n",
        "print(\"Average Cross Validation score :{}\".format(score.mean()))"
      ],
      "metadata": {
        "id": "Hp0F_Sw089Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier(criterion=\"gini\", random_state=42,max_depth=3, min_samples_leaf=5)  \n",
        "shuffle_split = ShuffleSplit(test_size=0.3, train_size=0.5, n_splits=10)\n",
        "scores = cross_val_score(clf, inputAttributes, outputAttribute, cv=shuffle_split)\n",
        "print(\"cross Validation scores:n {}\".format(scores))\n",
        "print(\"Average Cross Validation score :{}\".format(scores.mean()))"
      ],
      "metadata": {
        "id": "LFsRleyy_sl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newDf = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/Book2.csv')\n",
        "print(newDf)\n",
        "\n",
        "for i in newDf:\n",
        "  newDf['beard'] = newDf['beard'].replace(['yes'], 2222)\n",
        "  newDf['beard'] = newDf['beard'].replace(['no'], 1111)\n",
        "  newDf['hair_length'] = newDf['hair_length'].replace(['bald'], 11111)\n",
        "  newDf['hair_length'] = newDf['hair_length'].replace(['short'], 22222)\n",
        "  newDf['hair_length'] = newDf['hair_length'].replace(['medium'], 33333)\n",
        "  newDf['hair_length'] = newDf['hair_length'].replace(['long'], 44444)\n",
        "  newDf['scarf'] = newDf['scarf'].replace(['yes'], 222222)\n",
        "  newDf['scarf'] = newDf['scarf'].replace(['no'], 111111)\n",
        "  newDf['eye_color'] = newDf['eye_color'].replace(['black'], 1111111)\n",
        "  newDf['eye_color'] = newDf['eye_color'].replace(['blue'], 2222222)\n",
        "  newDf['eye_color'] = newDf['eye_color'].replace(['brown'], 3333333)\n",
        "  newDf['eye_color'] = newDf['eye_color'].replace(['gray'], 4444444)\n",
        "  newDf['eye_color'] = newDf['eye_color'].replace(['green'], 5555555)\n",
        "  newDf['gender'] = newDf['gender'].replace(['male'], 11111111)\n",
        "  newDf['gender'] = newDf['gender'].replace(['female'], 22222222)\n",
        "print(newDf)"
      ],
      "metadata": {
        "id": "nP_vEAlwHard"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain = dataset.iloc[:,:7]\n",
        "yTrain = dataset.iloc[:, 7]\n",
        "xTest = newDf.iloc[:, :7]\n",
        "yTest = newDf.iloc[:, 7]"
      ],
      "metadata": {
        "id": "7Wi-mU0qIlnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnb = GaussianNB()\n",
        "gnb.fit(xTrain, yTrain).predict(xTest)\n",
        "yPred = gnb.predict(xTest)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(yTest, yPred))"
      ],
      "metadata": {
        "id": "Ts3BeXkALw-n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}